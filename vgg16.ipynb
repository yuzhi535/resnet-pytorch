{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGT3fihuIJ9s9xcD1b70WY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuzhi535/resnet-pytorch/blob/master/vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQnxkmZ9bOiU",
        "outputId": "ad2ac789-d0d4-46a2-b88a-856eecfc7a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'resnet-pytorch'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 46 (delta 18), reused 35 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yuzhi535/resnet-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd resnet-pytorch\n",
        "%pip install timm einops torchmetrics albumentations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj1nk41UbTR8",
        "outputId": "b74d7c61-c4ad-4a22-eda0-a9a22001758c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/resnet-pytorch\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[K     |████████████████████████████████| 509 kB 21.4 MB/s \n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.1+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (6.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.6.0.66)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.7.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Installing collected packages: torchmetrics, timm, einops\n",
            "Successfully installed einops-0.4.1 timm-0.6.7 torchmetrics-0.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import os\n",
        "import torchmetrics\n",
        "from argparse import ArgumentParser\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from utils.dataloader import get_CIFAdataset_loader\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from networks.resnet import Resnet, Restnet34\n",
        "from networks.vgg import VGG16"
      ],
      "metadata": {
        "id": "mhokTfVtbhkv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "\n",
        "def arg_parser():\n",
        "    parser = ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--batch-size', '-bs', type=int,\n",
        "                        default=16, required=True, help='input batch size')\n",
        "    parser.add_argument('--num-workers', '-nw',  type=int,\n",
        "                        default=4, required=True, help='number of workers')\n",
        "    # parser.add_argument('--resume', '-r', type=str,\n",
        "    #                     required=False, help='resume a train')\n",
        "    parser.add_argument('--device', type=str,\n",
        "                        help='gpu or cpu', choices=['gpu', 'cpu'], default='gpu')\n",
        "    parser.add_argument('--num-classes', '-nc', type=int,\n",
        "                        help='number of classes', required=True)\n",
        "    parser.add_argument('--lr', '-lr', type=float, default=1e-4)\n",
        "    parser.add_argument('--epochs', type=int,\n",
        "                        required=True,  help='num of epochs')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "def train_fn(net, dataloader, opt, device, criterion, writer, epoch):\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    criterion.to(device)\n",
        "    for idx, (input, target) in dataloader:\n",
        "        input = input.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        pred = net(input)\n",
        "\n",
        "        loss = criterion(pred, target)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        cur_loss = train_loss/(idx+1)\n",
        "\n",
        "        dataloader.set_postfix(loss=cur_loss)\n",
        "        writer.add_scalar('training loss',\n",
        "                          cur_loss,\n",
        "                          epoch*len(dataloader)+idx)\n",
        "\n",
        "\n",
        "def val_fn(net, dataloader, device, num_classes, writer, epoch: int):\n",
        "    net.eval()\n",
        "    metric = torchmetrics.Accuracy(numClass=num_classes).to(device)\n",
        "    with torch.no_grad():\n",
        "        for idx, (input, target) in dataloader:\n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "            pred = net(input)\n",
        "            acc = metric.update(pred, target)\n",
        "    acc = metric.compute()\n",
        "    writer.add_scalar('val_acc', acc, epoch*len(dataloader)+idx)\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train(net, opt, epochs, batch_size, num_workers, device, num_classes, model='Resnet', scheduler=None):\n",
        "\n",
        "    train_dataloader, val_dataloader, _ = get_CIFAdataset_loader(\n",
        "        root='./data/CIFA', batch_size=batch_size, num_workers=num_workers, pin_memory=True, valid_rate=0.2, shuffle=True)\n",
        "\n",
        "    # 模型权重位置\n",
        "    model_path = 'runs'\n",
        "    if not os.path.exists(model_path):\n",
        "        os.mkdir(model_path)\n",
        "    save_path = os.path.join(model_path, model)\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "        os.mkdir(save_path)\n",
        "\n",
        "    log_dir = os.path.join(model_path,  model, 'logs')\n",
        "    if not os.path.exists(log_dir):\n",
        "        os.mkdir(log_dir)\n",
        "\n",
        "    writer = SummaryWriter(log_dir)\n",
        "\n",
        "    net.to(device)\n",
        "\n",
        "    best = 0.0\n",
        "\n",
        "    early_stop_step = 0\n",
        "    early_stop_limit = 15\n",
        "\n",
        "    for idx in range(epochs):\n",
        "        train_loop = tqdm(enumerate(train_dataloader),\n",
        "                          total=len(train_dataloader), leave=True)\n",
        "        train_loop.set_description(f'epoch: {idx}/{epochs}')\n",
        "\n",
        "        train_fn(net=net, opt=opt,\n",
        "                 dataloader=train_loop, device=device,\n",
        "                 criterion=nn.CrossEntropyLoss(),\n",
        "                 writer=writer, epoch=idx,\n",
        "                 )\n",
        "\n",
        "        val_loop = tqdm(enumerate(val_dataloader),\n",
        "                        total=len(val_dataloader), leave=True)\n",
        "\n",
        "        score = val_fn(net=net, dataloader=val_loop,\n",
        "                       device=device, num_classes=num_classes, writer=writer, epoch=idx)\n",
        "\n",
        "        print(f'acc={score}, best acc is {max(score, best)}')\n",
        "\n",
        "        if (score > best):\n",
        "            torch.save({\n",
        "                'epoch': idx,\n",
        "                'model_state_dict': net.state_dict(),\n",
        "                'optimizer_state_dict': opt.state_dict(),\n",
        "            }, os.path.join(save_path, f'epoch={idx}-miou={score:.4f}.pth'))\n",
        "            best = score\n",
        "            early_stop_step = 0\n",
        "        else:\n",
        "            if early_stop_step > early_stop_limit:\n",
        "                print(f'因为已经有{early_stop_limit}轮没有提升，训练提前终止')\n",
        "                writer.close()\n",
        "                break\n",
        "            early_stop_step += 1\n",
        "\n",
        "        if scheduler:\n",
        "            writer.add_scalar(\n",
        "                \"lr\", scheduler.get_last_lr()[-1]\n",
        "            )\n",
        "            scheduler.step()\n",
        "    writer.close()"
      ],
      "metadata": {
        "id": "vQnYhhp7bn6M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # args = arg_parser()\n",
        "    bs = 32  # args.batch_size\n",
        "    num_workers = 2  # args.num_workers\n",
        "    device = 'cuda:0'  # args.device\n",
        "    num_classes = 10  # args.num_classes\n",
        "    lr = 0.001  # args.num_classes\n",
        "    epochs = 10  # args.epochs\n",
        "    # net = Resnet(num_classes, [3, 4, 6, 3], [16, 32, 64, 128])\n",
        "    net = VGG16()\n",
        "    opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    seed_everything(42)\n",
        "    train(net=net, epochs=epochs, batch_size=bs, num_workers=num_workers,\n",
        "          device=device, num_classes=num_classes, opt=opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UynDIfjTbucH",
        "outputId": "5bde1c93-872e-4829-b899-f1e5e5e46964"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch: 0/10: 100%|██████████| 1250/1250 [00:48<00:00, 25.88it/s, loss=1.83]\n",
            "100%|██████████| 313/313 [00:05<00:00, 60.65it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc=0.41990000009536743, best acc is 0.41990000009536743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 1/10: 100%|██████████| 1250/1250 [00:40<00:00, 30.75it/s, loss=1.34]\n",
            "100%|██████████| 313/313 [00:04<00:00, 63.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.5759000182151794, best acc is 0.5759000182151794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 2/10: 100%|██████████| 1250/1250 [00:38<00:00, 32.29it/s, loss=1.04]\n",
            "100%|██████████| 313/313 [00:05<00:00, 56.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.6572999954223633, best acc is 0.6572999954223633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 3/10: 100%|██████████| 1250/1250 [00:38<00:00, 32.30it/s, loss=0.905]\n",
            "100%|██████████| 313/313 [00:04<00:00, 64.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.6949999928474426, best acc is 0.6949999928474426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 4/10: 100%|██████████| 1250/1250 [00:39<00:00, 32.03it/s, loss=0.798]\n",
            "100%|██████████| 313/313 [00:04<00:00, 63.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.7276999950408936, best acc is 0.7276999950408936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 5/10: 100%|██████████| 1250/1250 [00:38<00:00, 32.19it/s, loss=0.703]\n",
            "100%|██████████| 313/313 [00:04<00:00, 65.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.7849000096321106, best acc is 0.7849000096321106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 6/10: 100%|██████████| 1250/1250 [00:38<00:00, 32.68it/s, loss=0.629]\n",
            "100%|██████████| 313/313 [00:04<00:00, 64.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.7882000207901001, best acc is 0.7882000207901001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 7/10: 100%|██████████| 1250/1250 [00:39<00:00, 31.81it/s, loss=0.571]\n",
            "100%|██████████| 313/313 [00:04<00:00, 65.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.8109999895095825, best acc is 0.8109999895095825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 8/10: 100%|██████████| 1250/1250 [00:38<00:00, 32.08it/s, loss=0.527]\n",
            "100%|██████████| 313/313 [00:04<00:00, 64.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.8119000196456909, best acc is 0.8119000196456909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch: 9/10: 100%|██████████| 1250/1250 [00:38<00:00, 32.29it/s, loss=0.483]\n",
            "100%|██████████| 313/313 [00:05<00:00, 56.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc=0.8256000280380249, best acc is 0.8256000280380249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 模型评估"
      ],
      "metadata": {
        "id": "oyiT3DgZcNOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, dataloader, device, num_classes):\n",
        "    from torch.nn import functional as F\n",
        "    net.eval()\n",
        "    # metric = torchmetrics.Accuracy(numClass=num_classes).to(device)\n",
        "    correct=0.0\n",
        "    with torch.no_grad():\n",
        "        for  _, (input, target) in tqdm(enumerate(dataloader), total=len(dataloader), leave=True):\n",
        "            input = input.to(device)\n",
        "            target = target.to(device)\n",
        "            pred = net(input)\n",
        "            pred = F.softmax(pred, 1).argmax(1)\n",
        "            correct += pred.eq(target).sum()\n",
        "            # acc = metric.update(pred, target)\n",
        "    # acc = metric.compute()\n",
        "    print(correct / len(dataloader))\n",
        "\n",
        "_, _, test_dataloader = get_CIFAdataset_loader(\n",
        "        root='./data/CIFA', batch_size=128, num_workers=2, pin_memory=True, valid_rate=0.2, shuffle=True)\n",
        "\n",
        "test(net=net, device=device, num_classes=num_classes, dataloader=test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpv8R6QmbzPX",
        "outputId": "df700a1c-9795-43d1-a0e1-f16a92dd0f2e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:52<00:00, 191.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8342, device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}